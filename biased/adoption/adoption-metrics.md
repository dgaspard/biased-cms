<!--
AI AGENT METADATA:
@purpose: Track user adoption and engagement with AI system. Measures real-world usage and acceptance.
@audience: Product managers, AI agents, stakeholders
@format: List of key adoption metrics to track
@required_sections: Metric definitions
@related_files: ["biased/intent/intent.md (adoption targets)", "biased/adoption/workflow-map.md (user workflows)", "biased/metrics/weekly-metrics.json (data collection)"]
@update_frequency: Weekly during Adoption & Change Review
@instructions: AI agents should monitor these metrics to assess system value. Alert if adoption drops suddenly. Use feedback to identify improvement areas.
-->

# Adoption Metrics

Track weekly during Adoption & Change Review.

## Key Metrics

- **Adoption rate**: % of target users actively using the system
- **Override/correction rate**: How often users modify AI outputs
- **Trust score**: User confidence in AI outputs (survey or UX signal)
- **Time saved per workflow**: Efficiency gain measurement
- **Active users**: Daily/weekly active user counts
- **Feature usage**: Which features are used most

**AI Agent Instructions:**
- Monitor weekly trends, not just point-in-time values
- Investigate drops in adoption or trust scores
- Correlate override rate with behavior changes
- Use adoption data to prioritize feature development
